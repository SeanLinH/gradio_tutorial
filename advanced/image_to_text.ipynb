{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 實作image to text \n",
    "於Huggingface 上探索模型來測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "!pip install transformers\n",
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/linshihuan/Dev/.gradio/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 4.56k/4.56k [00:00<00:00, 3.98MB/s]\n",
      "pytorch_model.bin: 100%|██████████| 990M/990M [00:58<00:00, 16.8MB/s] \n",
      "/Users/linshihuan/Dev/.gradio/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "tokenizer_config.json: 100%|██████████| 506/506 [00:00<00:00, 443kB/s]\n",
      "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 560kB/s]\n",
      "tokenizer.json: 100%|██████████| 711k/711k [00:00<00:00, 890kB/s]\n",
      "special_tokens_map.json: 100%|██████████| 125/125 [00:00<00:00, 155kB/s]\n",
      "preprocessor_config.json: 100%|██████████| 287/287 [00:00<00:00, 696kB/s]\n",
      "/Users/linshihuan/Dev/.gradio/lib/python3.11/site-packages/transformers/generation/utils.py:1133: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a puppy sitting in the grass with its mouth open\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'a puppy sitting in the grass with its mouth open'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def img2text(url):\n",
    "    img_2_text = pipeline(\"image-to-text\", model=\"Salesforce/blip-image-captioning-base\")\n",
    "    text = img_2_text(url)[0][\"generated_text\"]\n",
    "    print(text)\n",
    "    return text\n",
    "\n",
    "img2text('dog.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Image to text\n",
    "import gradio as gr\n",
    "\n",
    "title = \"圖像 to 文字\"\n",
    "\n",
    "def generateAudio(url):\n",
    "    result = img2text(url)\n",
    "    return result\n",
    "\n",
    "img_input = gr.Image(type=\"filepath\")\n",
    "app = gr.Interface(fn=generateAudio, inputs=img_input , outputs=\"text\", title=title)\n",
    "app.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".gradio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
