{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/linshihuan/Dev/.gradio/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "from transformers import pipeline\n",
    "import os\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "hf_api_key = os.environ['HF_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 4.56k/4.56k [00:00<00:00, 4.83MB/s]\n",
      "pytorch_model.bin: 100%|██████████| 990M/990M [00:57<00:00, 17.1MB/s] \n",
      "/Users/linshihuan/Dev/.gradio/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "tokenizer_config.json: 100%|██████████| 506/506 [00:00<00:00, 2.89MB/s]\n",
      "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 603kB/s]\n",
      "tokenizer.json: 100%|██████████| 711k/711k [00:00<00:00, 1.03MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 125/125 [00:00<00:00, 363kB/s]\n",
      "preprocessor_config.json: 100%|██████████| 287/287 [00:00<00:00, 881kB/s]\n",
      "/Users/linshihuan/Dev/.gradio/lib/python3.11/site-packages/transformers/generation/utils.py:1133: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a puppy sitting in the grass with its mouth open\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'a puppy sitting in the grass with its mouth open'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def img2text(url):\n",
    "    img_2_text = pipeline(\"image-to-text\", model=\"Salesforce/blip-image-captioning-base\")\n",
    "    text = img_2_text(url)[0][\"generated_text\"]\n",
    "    print(text)\n",
    "    return text\n",
    "\n",
    "img2text('dog.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/linshihuan/Dev/.gradio/lib/python3.11/site-packages/transformers/generation/utils.py:1133: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a puppy sitting in the grass with its mouth open\n"
     ]
    }
   ],
   "source": [
    "## Speech to text\n",
    "import gradio as gr\n",
    "\n",
    "title = \"圖像 to 文字\"\n",
    "\n",
    "def generateAudio(url):\n",
    "    result = img2text(url)\n",
    "    return result\n",
    "\n",
    "img_input = gr.Image(type=\"filepath\")\n",
    "app = gr.Interface(fn=generateAudio, inputs=img_input , outputs=\"text\", title=title)\n",
    "app.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".gradio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
